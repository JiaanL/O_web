{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import django\n",
    "os.environ.setdefault('DJANGO_SETTINGS_MODULE', 'rest.settings')\n",
    "os.environ[\"DJANGO_ALLOW_ASYNC_UNSAFE\"] = \"true\"\n",
    "django.setup()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import django\n",
    "from django.db.models import Max, Min, Avg, Q, F\n",
    "from asgiref.sync import sync_to_async\n",
    "import tqdm\n",
    "from collections import defaultdict\n",
    "from pandarallel import pandarallel\n",
    "import requests\n",
    "import json\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "import ctypes\n",
    "from ctypes import c_char_p, cdll\n",
    "GoInt64 = ctypes.c_int64\n",
    "GoInt = GoInt64\n",
    "archive_node = \"http://localhost:19545\"\n",
    "\n",
    "from etherscan.utils.parsing import ResponseParser as parser\n",
    "pandarallel.initialize(progress_bar=True)\n",
    "# os.environ.setdefault('DJANGO_SETTINGS_MODULE', 'rest.settings')\n",
    "# os.environ[\"DJANGO_ALLOW_ASYNC_UNSAFE\"] = \"true\"\n",
    "# django.setup()\n",
    "\n",
    "from debtmonitor.models import *\n",
    "from datavisualization.models import *\n",
    "from datastorage.models import *\n",
    "from debtmonitor.help_function import *\n",
    "\n",
    "import debtmonitor.views as dm\n",
    "import datavisualization.views as dv\n",
    "import datastorage.views as ds\n",
    "import oracleWeb.views as ow\n",
    "\n",
    "from debtmonitor.debt_function import *\n",
    "\n",
    "import pickle\n",
    "\n",
    "pandarallel.initialize(progress_bar=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# VAR predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gen_predict_hf(reserves_status, TargetContract, ReservesStatusEnd, StepAhead, MCAmount, ReservesStatusEndIndex, PreviousBlockForTrain):\n",
    "\n",
    "    # reserves_status = get_reserves_status()\n",
    "    latest_block_num = reserves_status['block_num'].max()\n",
    "    interaction_df = get_interaction_data(TargetContract)\n",
    "\n",
    "    until_block_num = latest_block_num\n",
    "    until_block_num = ReservesStatusEnd\n",
    "    until_index = ReservesStatusEndIndex\n",
    "\n",
    "    until_block_n_index = combine_block_n_index({'block_num': until_block_num, 'index': until_index})\n",
    "    # liquidation_index = until_index\n",
    "\n",
    "    # Start Getting Data #####################################\n",
    "    liquidation_df = get_liquidation_call(TargetContract)\n",
    "\n",
    "    # reserves_status['variable_borrow_rate'] = reserves_status['variable_borrow_rate'].astype(int)\n",
    "    # reserves_status['stable_borrow_rate'] = reserves_status['stable_borrow_rate'].astype(int)\n",
    "    # reserves_status['liquidity_rate'] = reserves_status['liquidity_rate'].astype(int)\n",
    "    # liquidation_df['debt_to_cover'] = liquidation_df['debt_to_cover'].astype(int)\n",
    "    # liquidation_df['liquidated_collateral_amount'] = liquidation_df['liquidated_collateral_amount'].astype(int)\n",
    "    # interaction_df['amount'] = interaction_df['amount'].astype(int)\n",
    "\n",
    "    interaction_df = interaction_df['action block_num index on_behalf_of reserve amount rate_mode rate'.split(' ')].copy()\n",
    "    reserves_status = reserves_status[[\n",
    "        'reserve', 'block_num', 'index',  \n",
    "        'liquidity_rate', 'stable_borrow_rate', 'variable_borrow_rate', \n",
    "        'liquidity_index','variable_borrow_index'\n",
    "    ]].copy()\n",
    "    liquidation_df = liquidation_df[[\n",
    "        'block_num', 'index', 'on_behalf_of', \n",
    "        'collateral_asset', 'debt_asset', 'debt_to_cover', 'liquidated_collateral_amount',\n",
    "        'liquidator', 'receive_atoken']].copy()\n",
    "\n",
    "    interaction_df['block_n_index'] = interaction_df.apply(combine_block_n_index, axis=1)\n",
    "    reserves_status['block_n_index'] = reserves_status.apply(combine_block_n_index, axis=1)\n",
    "    liquidation_df['block_n_index'] = liquidation_df.apply(combine_block_n_index, axis=1)\n",
    "\n",
    "    interaction_df = interaction_df.sort_values('block_n_index').reset_index(drop=True)\n",
    "    reserves_status = reserves_status.sort_values('block_n_index').reset_index(drop=True)\n",
    "\n",
    "\n",
    "    # just give a random reserve address, will be swich in the following part\n",
    "    for index in interaction_df.index:\n",
    "        if interaction_df.loc[index, 'action'] == \"LiquidationCall\":\n",
    "            interaction_df.loc[index, 'reserve'] = '0xa0b86991c6218b36c1d19d4a2e9eb0ce3606eb48'\n",
    "\n",
    "    # merge\n",
    "    user_df = interaction_df.merge(reserves_status, on=['reserve'], how='left')\n",
    "    change_token_address_to_name = lambda x: revert_token_dict[x] if x in revert_token_dict else x\n",
    "    interaction_df['reserve'] = interaction_df['reserve'].apply(change_token_address_to_name).reset_index(drop=True)\n",
    "    user_df['reserve'] = user_df['reserve'].apply(change_token_address_to_name).reset_index(drop=True)\n",
    "    reserves_status['reserve'] = reserves_status['reserve'].apply(change_token_address_to_name).reset_index(drop=True)\n",
    "\n",
    "    liquidation_df['collateral_asset'] = liquidation_df['collateral_asset'].apply(change_token_address_to_name)\n",
    "    liquidation_df['debt_asset'] = liquidation_df['debt_asset'].apply(change_token_address_to_name)\n",
    "\n",
    "\n",
    "    def get_liquidation_data(df_row):\n",
    "        df_row = df_row.copy()\n",
    "        if df_row['action'] != 'LiquidationCall': return df_row\n",
    "        # collateral\n",
    "        block_n_index_x = df_row['block_n_index_x']\n",
    "        liquidation_row = liquidation_df[liquidation_df['block_n_index'] == block_n_index_x]\n",
    "        collateral_asset = liquidation_row['collateral_asset'].values[0]\n",
    "        tmp_reserves_status = reserves_status[\\\n",
    "            (reserves_status['reserve'] == collateral_asset) &\\\n",
    "            (reserves_status['block_n_index'] <= block_n_index_x)].copy().sort_values('block_n_index')\n",
    "        tmp_reserves_status = tmp_reserves_status.iloc[-1, :]\n",
    "\n",
    "        df_row['block_num_y'] = tmp_reserves_status['block_num']\n",
    "        df_row['index_y'] = tmp_reserves_status['index']\n",
    "        df_row['liquidity_rate'] = tmp_reserves_status['liquidity_rate']\n",
    "        df_row['liquidity_index'] = tmp_reserves_status['liquidity_index']\n",
    "        df_row['block_n_index_y'] = tmp_reserves_status['block_n_index']\n",
    "\n",
    "        debt_asset = liquidation_row['debt_asset'].values[0]\n",
    "        tmp_reserves_status = reserves_status[\\\n",
    "            (reserves_status['reserve'] == debt_asset) &\\\n",
    "            (reserves_status['block_n_index'] <= block_n_index_x)].copy().sort_values('block_n_index')\n",
    "        tmp_reserves_status = tmp_reserves_status.iloc[-1, :]\n",
    "\n",
    "        df_row['stable_borrow_rate'] = tmp_reserves_status['stable_borrow_rate']\n",
    "        df_row['variable_borrow_rate'] = tmp_reserves_status['variable_borrow_rate']\n",
    "        df_row['variable_borrow_index'] = tmp_reserves_status['variable_borrow_index']\n",
    "        \n",
    "        return df_row\n",
    "    \n",
    "    from_df = user_df[user_df['block_n_index_y'] <= user_df['block_n_index_x']]\n",
    "    from_df = from_df.loc[from_df.groupby('block_n_index_x').block_n_index_y.idxmax()].reset_index(drop=True)\n",
    "    from_df = from_df.apply(get_liquidation_data, axis=1)\n",
    "\n",
    "\n",
    "    # a token\n",
    "    collateral_dict = defaultdict(float)\n",
    "    collatearl_able_dict = defaultdict(lambda :True)\n",
    "    variable_debt_dict = defaultdict(float)\n",
    "    stable_debt_dict = defaultdict(lambda : [None, None, None]) # amount, interest, start time\n",
    "\n",
    "    sub_interaction_df = interaction_df[interaction_df['block_n_index'] <= until_block_n_index].copy()\n",
    "\n",
    "    for index_i in sub_interaction_df.index:\n",
    "\n",
    "        action_i = sub_interaction_df.loc[index_i, 'action']\n",
    "        block_n_index = sub_interaction_df.loc[index_i, 'block_n_index']\n",
    "        block_num = sub_interaction_df.loc[index_i, 'block_num']\n",
    "        index = sub_interaction_df.loc[index_i, 'index']\n",
    "\n",
    "        # block_time = get_block_time(block_num)\n",
    "        before_data = from_df[from_df['block_n_index_x'] == block_n_index]#['amount'].values[0]\n",
    "        liquidity_index = before_data['liquidity_index'].values[0]\n",
    "        variable_borrow_index = before_data['variable_borrow_index'].values[0]\n",
    "        stable_borrow_rate = before_data['stable_borrow_rate'].values[0]\n",
    "        \n",
    "        if action_i == \"LiquidationCall\":\n",
    "            'collateral_asset', 'debt_asset', 'debt_to_cover', 'liquidated_collateral_amount',\n",
    "            liquidation_i = liquidation_df[liquidation_df['block_n_index'] == block_n_index].copy().reset_index(drop=True)\n",
    "            collateral_asset = liquidation_i.loc[0, 'collateral_asset']\n",
    "            debt_asset = liquidation_i.loc[0, 'debt_asset']\n",
    "            debt_to_cover = liquidation_i.loc[0, 'debt_to_cover']\n",
    "            liquidated_collateral_amount = liquidation_i.loc[0, 'liquidated_collateral_amount']\n",
    "\n",
    "            # a_token_amount_i = ray_div(liquidated_collateral_amount, liquidity_index)\n",
    "            # collateral_dict[collateral_asset] -= a_token_amount_i\n",
    "\n",
    "            collateral_in_original_unit, var_debt_in_original_unit, sta_debt_in_original_unit = get_token_value(\n",
    "                block_num, index,\n",
    "                collateral_dict, collatearl_able_dict, variable_debt_dict, stable_debt_dict,reserves_status\n",
    "            )\n",
    "\n",
    "            if var_debt_in_original_unit[debt_asset] < debt_to_cover:\n",
    "                var_debt_to_liquidate = var_debt_in_original_unit[debt_asset]\n",
    "                sta_debt_to_repay = debt_to_cover - var_debt_to_liquidate\n",
    "            else:\n",
    "                var_debt_to_liquidate = debt_to_cover\n",
    "                sta_debt_to_repay = 0\n",
    "\n",
    "            success, remaining_token = update_target_debt_data(\n",
    "                    \"Repay\", block_num, var_debt_to_liquidate, debt_asset, \n",
    "                    \"2\", liquidity_index, variable_borrow_index, stable_borrow_rate,\n",
    "                    collateral_dict, collatearl_able_dict, variable_debt_dict, stable_debt_dict\n",
    "                )\n",
    "            assert success\n",
    "\n",
    "            if sta_debt_to_repay > 0:\n",
    "                success, remaining_token = update_target_debt_data(\n",
    "                    \"Repay\", block_num, sta_debt_to_repay, debt_asset, \n",
    "                    \"1\", liquidity_index, variable_borrow_index, stable_borrow_rate,\n",
    "                    collateral_dict, collatearl_able_dict, variable_debt_dict, stable_debt_dict\n",
    "                )\n",
    "                assert success\n",
    "            \n",
    "            success, remaining_token = update_target_debt_data(\n",
    "                \"Withdraw\", block_num, liquidated_collateral_amount, collateral_asset, \n",
    "                \"-1\", liquidity_index, variable_borrow_index, stable_borrow_rate,\n",
    "                collateral_dict, collatearl_able_dict, variable_debt_dict, stable_debt_dict\n",
    "            )\n",
    "            assert success\n",
    "\n",
    "        else:\n",
    "            amount_i = sub_interaction_df.loc[index_i, 'amount']\n",
    "            token_name_i = sub_interaction_df.loc[index_i, 'reserve']\n",
    "            rate_mode_i = sub_interaction_df.loc[index_i, 'rate_mode']\n",
    "\n",
    "            update_target_debt_data(action_i, block_num, amount_i, token_name_i, \n",
    "            rate_mode_i, liquidity_index, variable_borrow_index, stable_borrow_rate,\n",
    "            collateral_dict, collatearl_able_dict, variable_debt_dict, stable_debt_dict)\n",
    "    \n",
    "    \n",
    "    token_value_dicts = get_token_value(until_block_num, until_index, \n",
    "                            collateral_dict, collatearl_able_dict, variable_debt_dict, stable_debt_dict,\n",
    "                            reserves_status,\n",
    "                            fix_decimal=True\n",
    "                        )\n",
    "\n",
    "    # collateral, var_debt, sta_debt\n",
    "    token_value_dicts = {i:j for i,j in zip(['collateral', 'var_debt', 'sta_debt'], token_value_dicts)}\n",
    "\n",
    "    price_data = get_price_data(until_block_num, previous_block= 6424*1 + PreviousBlockForTrain)\n",
    "    # price_data = get_price_data(until_block_num, previous_block=PreviousBlockForTrain)\n",
    "    price_data['token0'] = price_data['token0'].apply(lambda x: 'weth' if x == 'eth' else x)\n",
    "    price_data['token1'] = price_data['token1'].apply(lambda x: 'weth' if x == 'eth' else x)\n",
    "    price_data = price_data[['block_num', 'oracle_name', 'token0', 'token1', 'current']]\n",
    "\n",
    "    block_num_df = pd.DataFrame(\n",
    "        range(\n",
    "            price_data.block_num.min(), \n",
    "            until_block_num + 1\n",
    "        ),\n",
    "        columns=['block_num']\n",
    "    )\n",
    "    block_num_df.set_index('block_num', inplace=True)\n",
    "\n",
    "    uniswapv3_price_dict = {}\n",
    "    for token in ['usdt', 'dai', 'usdc']:\n",
    "        sub_price_df = price_data[(price_data['oracle_name'] == 'uniswapv3') & (price_data['token1'] == token)].copy()\n",
    "        sub_price_df[f'{token}'] = 1/sub_price_df['current']\n",
    "        sub_price_df.set_index('block_num', inplace=True)\n",
    "        sub_price_df = sub_price_df.merge(block_num_df, how='right', left_index=True, right_index=True)\n",
    "        sub_price_df.fillna(method='ffill', inplace=True)\n",
    "        sub_price_df.fillna(method='bfill', inplace=True)\n",
    "        sub_price_df = sub_price_df[sub_price_df.index > (until_block_num-PreviousBlockForTrain-1)]\n",
    "        uniswapv3_price_dict[token] = sub_price_df[token]\n",
    "    chainlink_price_dict ={}\n",
    "    for token in ['usdt', 'dai', 'usdc']:\n",
    "        sub_price_df = price_data[(price_data['oracle_name'] == 'chainlink') & (price_data['token0'] == token)].copy()\n",
    "        sub_price_df[f'{token}'] = sub_price_df['current']\n",
    "        sub_price_df.set_index('block_num', inplace=True)\n",
    "        sub_price_df = sub_price_df.merge(block_num_df, how='right', left_index=True, right_index=True)\n",
    "        sub_price_df.fillna(method='ffill', inplace=True)\n",
    "        sub_price_df.fillna(method='bfill', inplace=True)\n",
    "        sub_price_df = sub_price_df[sub_price_df.index > (until_block_num-PreviousBlockForTrain-1)]\n",
    "        chainlink_price_dict[token] = sub_price_df[token]\n",
    "\n",
    "    # collatearl_in_eth = 0\n",
    "    # debt_in_eth = 0\n",
    "    # for token_name, token_amount in token_value_dicts['collateral'].items():\n",
    "    #     if token_name == 'weth':\n",
    "    #         collatearl_in_eth += token_amount\n",
    "    #     else:\n",
    "    #         collatearl_in_eth += token_amount * chainlink_price_dict[token_name].loc[until_block_num]\n",
    "\n",
    "    # for token_name, token_amount in token_value_dicts['var_debt'].items():\n",
    "    #     if token_name == 'weth':\n",
    "    #         debt_in_eth += token_amount\n",
    "    #     else:\n",
    "    #         debt_in_eth += token_amount * chainlink_price_dict[token_name].loc[until_block_num]\n",
    "\n",
    "    # for token_name, token_amount in token_value_dicts['sta_debt'].items():\n",
    "    #     if token_name == 'weth':\n",
    "    #         debt_in_eth += token_amount\n",
    "    #     else:\n",
    "    #         debt_in_eth += token_amount * chainlink_price_dict[token_name].loc[until_block_num]\n",
    "\n",
    "    # collatearl_m_threshold_in_eth = 0\n",
    "    # debt_m_threshold_in_eth = 0\n",
    "    # for token_name, token_amount in token_value_dicts['collateral'].items():\n",
    "    #     if token_name == 'weth':\n",
    "    #         collatearl_m_threshold_in_eth += token_amount * liquidation_threshold_dict[token_name]\n",
    "    #     else:\n",
    "    #         collatearl_m_threshold_in_eth += token_amount * chainlink_price_dict[token_name].loc[until_block_num]  * liquidation_threshold_dict[token_name]\n",
    "\n",
    "    # for token_name, token_amount in token_value_dicts['var_debt'].items():\n",
    "    #     if token_name == 'weth':\n",
    "    #         debt_m_threshold_in_eth += token_amount\n",
    "    #     else:\n",
    "    #         debt_m_threshold_in_eth += token_amount * chainlink_price_dict[token_name].loc[until_block_num]\n",
    "\n",
    "    # for token_name, token_amount in token_value_dicts['sta_debt'].items():\n",
    "    #     if token_name == 'weth':\n",
    "    #         debt_m_threshold_in_eth += token_amount\n",
    "    #     else:\n",
    "    #         debt_m_threshold_in_eth += token_amount * chainlink_price_dict[token_name].loc[until_block_num]\n",
    "    # collatearl_m_threshold_in_eth, debt_m_threshold_in_eth\n",
    "\n",
    "    # testtt = interaction_df[['action', 'block_num', 'reserve', 'amount']]\n",
    "\n",
    "    # current_healthfactor = (collatearl_m_threshold_in_eth/debt_m_threshold_in_eth)\n",
    "\n",
    "    used_token_list = []\n",
    "    price_data_list = []\n",
    "    price_name_list = []\n",
    "    for asset_from in ['collateral', 'var_debt', 'sta_debt']:\n",
    "        for token_name in ['usdc', 'usdt', 'dai']:\n",
    "        # for token_name, token_amount in token_value_dicts[asset_from].items():\n",
    "            if token_name == 'weth': continue\n",
    "            if token_name not in used_token_list:\n",
    "                used_token_list.append(token_name)\n",
    "                price_data_list.append(chainlink_price_dict[token_name])\n",
    "                price_name_list.append(f'chainlink_{token_name}')\n",
    "                price_data_list.append(uniswapv3_price_dict[token_name])\n",
    "                price_name_list.append(f'uniswapv3_{token_name}')\n",
    "    var_train_df = pd.concat(price_data_list, axis=1)\n",
    "    var_train_df.columns = price_name_list\n",
    "    var_train_df = var_train_df.reset_index(drop=False)\n",
    "\n",
    "    # hf_actual_series = cal_hf(var_train_df, token_value_dicts, liquidation_threshold_dict)\n",
    "    # hf_actual_series.index = var_train_df['block_num']\n",
    "\n",
    "\n",
    "    train_data = var_train_df.set_index('block_num')\n",
    "    tmp_df = train_data.copy()\n",
    "    log_f_diff = tmp_df.diff().dropna() \n",
    "    log_f_diff = log_f_diff.reset_index(drop=True)\n",
    "    train_success = False\n",
    "\n",
    "    trained_var = get_var_result(log_f_diff, maxlags=None)\n",
    "\n",
    "    def mc_simulate(df, step=240):\n",
    "        price_diff_prediction = pd.DataFrame(trained_var.simulate_var(step), columns=log_f_diff.columns)\n",
    "        price_prediction = invert_transformation(tmp_df, price_diff_prediction) \n",
    "        hf_df = cal_hf(price_prediction, token_value_dicts, liquidation_threshold_dict)\n",
    "        return hf_df\n",
    "\n",
    "    mc_hf = pd.DataFrame(range(MCAmount)).parallel_apply(mc_simulate, args=(StepAhead,), axis=1).T\n",
    "    horizontal_liquidation_pct = pd.DataFrame(mc_hf.parallel_apply(cal_pct_be_liquidated, axis=1), columns=['hf'])#.plot()\n",
    "    # horizontal_liquidation_pct.columns = ['hf']\n",
    "    horizontal_liquidation_pct['block_num'] = pd.Series(range(ReservesStatusEnd, ReservesStatusEnd + StepAhead))\n",
    "\n",
    "    return horizontal_liquidation_pct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# GoInt64 = ctypes.c_int64\n",
    "# GoInt = GoInt64\n",
    "\n",
    "# # pandarallel.initialize(progress_bar=False)\n",
    "\n",
    "# __library = cdll.LoadLibrary('../eth_crawler/library.so')\n",
    "# get_aave_log = __library.get_aave_log\n",
    "# get_aave_log.argtypes = [c_char_p, GoInt, GoInt]\n",
    "# get_aave_log.restype = c_char_p\n",
    "\n",
    "# res = get_aave_log(\n",
    "#     # data_source.encode(), \n",
    "#     archive_node.encode(), \n",
    "#     GoInt(13054560), \n",
    "#     GoInt(13054560)\n",
    "# )\n",
    "# res"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Real HF cal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gen_real_hf(reserves_status, TargetContract, ReservesStatusEnd, StepAhead, ReservesStatusEndIndex, PreviousBlockForTrain=0, print_info=False):\n",
    "\n",
    "    # reserves_status = get_reserves_status()\n",
    "\n",
    "    # StepAhead += PreviousBlockForTrain\n",
    "    reserves_status = reserves_status.copy()\n",
    "    \n",
    "    latest_block_num = reserves_status['block_num'].max()\n",
    "    interaction_df = get_interaction_data(TargetContract)\n",
    "\n",
    "    until_block_num = latest_block_num\n",
    "    until_block_num = ReservesStatusEnd\n",
    "    until_index = ReservesStatusEndIndex\n",
    "\n",
    "    reserves_status = reserves_status[reserves_status['block_num'] <= ReservesStatusEnd]\n",
    "    until_block_n_index = combine_block_n_index({'block_num': until_block_num, 'index': until_index})\n",
    "    # liquidation_index = until_index\n",
    "\n",
    "    # Start Getting Data #####################################\n",
    "    liquidation_df = get_liquidation_call(TargetContract)\n",
    "\n",
    "    # reserves_status['variable_borrow_rate'] = reserves_status['variable_borrow_rate'].astype(int)\n",
    "    # reserves_status['stable_borrow_rate'] = reserves_status['stable_borrow_rate'].astype(int)\n",
    "    # reserves_status['liquidity_rate'] = reserves_status['liquidity_rate'].astype(int)\n",
    "    # liquidation_df['debt_to_cover'] = liquidation_df['debt_to_cover'].astype(int)\n",
    "    # liquidation_df['liquidated_collateral_amount'] = liquidation_df['liquidated_collateral_amount'].astype(int)\n",
    "    # interaction_df['amount'] = interaction_df['amount'].astype(int)\n",
    "\n",
    "    interaction_df = interaction_df['action block_num index on_behalf_of reserve amount rate_mode rate'.split(' ')].copy()\n",
    "    reserves_status = reserves_status[[\n",
    "        'reserve', 'block_num', 'index',  \n",
    "        'liquidity_rate', 'stable_borrow_rate', 'variable_borrow_rate', \n",
    "        'liquidity_index','variable_borrow_index'\n",
    "    ]].copy()\n",
    "    liquidation_df = liquidation_df[[\n",
    "        'block_num', 'index', 'on_behalf_of', \n",
    "        'collateral_asset', 'debt_asset', 'debt_to_cover', 'liquidated_collateral_amount',\n",
    "        'liquidator', 'receive_atoken']].copy()\n",
    "\n",
    "    interaction_df['block_n_index'] = interaction_df.apply(combine_block_n_index, axis=1)\n",
    "    reserves_status['block_n_index'] = reserves_status.apply(combine_block_n_index, axis=1)\n",
    "    liquidation_df['block_n_index'] = liquidation_df.apply(combine_block_n_index, axis=1)\n",
    "\n",
    "    interaction_df = interaction_df.sort_values('block_n_index').reset_index(drop=True)\n",
    "    reserves_status = reserves_status.sort_values('block_n_index').reset_index(drop=True)\n",
    "\n",
    "\n",
    "    # just give a random reserve address, will be swich in the following part\n",
    "    for index in interaction_df.index:\n",
    "        if interaction_df.loc[index, 'action'] == \"LiquidationCall\":\n",
    "            interaction_df.loc[index, 'reserve'] = '0xa0b86991c6218b36c1d19d4a2e9eb0ce3606eb48'\n",
    "\n",
    "    # merge\n",
    "\n",
    "\n",
    "    change_token_address_to_name = lambda x: revert_token_dict[x] if x in revert_token_dict else x\n",
    "    interaction_df['reserve'] = interaction_df['reserve'].apply(change_token_address_to_name).reset_index(drop=True)\n",
    "    reserves_status['reserve'] = reserves_status['reserve'].apply(change_token_address_to_name).reset_index(drop=True)\n",
    "    liquidation_df['collateral_asset'] = liquidation_df['collateral_asset'].apply(change_token_address_to_name)\n",
    "    liquidation_df['debt_asset'] = liquidation_df['debt_asset'].apply(change_token_address_to_name)\n",
    "\n",
    "\n",
    "    collateral_dict = defaultdict(float)\n",
    "    collatearl_able_dict = defaultdict(lambda :True)\n",
    "    variable_debt_dict = defaultdict(float)\n",
    "    stable_debt_dict = defaultdict(lambda : [None, None, None]) # amount, interest, start time\n",
    "\n",
    "    if print_info: print(interaction_df)\n",
    "\n",
    "    sub_interaction_df = interaction_df[interaction_df['block_n_index'] <= until_block_n_index].copy()\n",
    "    curent_block_index = 0\n",
    "    hf_list = []\n",
    "    block_list = []\n",
    "    have_data = False\n",
    "    block_n_index = None\n",
    "    interaction_block_list = sub_interaction_df['block_num'].to_list()\n",
    "    \n",
    "    # for tmp_block_num in tqdm.tqdm(reserves_status['block_num'].unique()):\n",
    "    for tmp_block_num in tqdm.tqdm(range(reserves_status['block_num'].min(), ReservesStatusEnd + StepAhead)):\n",
    "        if tmp_block_num not in interaction_block_list and tmp_block_num < (ReservesStatusEnd - PreviousBlockForTrain):\n",
    "            continue\n",
    "        until_block_num = tmp_block_num\n",
    "        tmp_reserves_status = reserves_status[reserves_status['block_num'] <= tmp_block_num]#.copy()\n",
    "        tmp_index = 9999\n",
    "        tmp_block_n_index = combine_block_n_index(dict(block_num=tmp_block_num, index=tmp_index))\n",
    "        sub_interaction_df = interaction_df[(interaction_df['block_n_index'] > curent_block_index) & (interaction_df['block_n_index'] <= tmp_block_n_index)].copy()\n",
    "        \n",
    "        update_value = False\n",
    "        for index_i in sub_interaction_df.index:\n",
    "            update_value = True\n",
    "            if print_info: print(sub_interaction_df.loc[index_i, :])\n",
    "            if print_info: print(tmp_reserves_status.iloc[-2:,:])\n",
    "            have_data = True\n",
    "            action_i = sub_interaction_df.loc[index_i, 'action']\n",
    "            block_n_index = sub_interaction_df.loc[index_i, 'block_n_index']\n",
    "            block_num = sub_interaction_df.loc[index_i, 'block_num']\n",
    "            index = sub_interaction_df.loc[index_i, 'index']\n",
    "\n",
    "            # block_time = get_block_time(block_num)\n",
    "            # before_data = from_df[from_df['block_n_index_x'] == block_n_index]#['amount'].values[0]\n",
    "            # liquidity_index = tmp_reserves_status['liquidity_index'].values[-1]\n",
    "            # variable_borrow_index = tmp_reserves_status['variable_borrow_index'].values[0]\n",
    "            # stable_borrow_rate = tmp_reserves_status['stable_borrow_rate'].values[0]\n",
    "            \n",
    "            if action_i == \"LiquidationCall\":\n",
    "                'collateral_asset', 'debt_asset', 'debt_to_cover', 'liquidated_collateral_amount',\n",
    "                liquidation_i = liquidation_df[liquidation_df['block_n_index'] == block_n_index].copy().reset_index(drop=True)\n",
    "                if print_info: print(liquidation_i)\n",
    "                collateral_asset = liquidation_i.loc[0, 'collateral_asset']\n",
    "                debt_asset = liquidation_i.loc[0, 'debt_asset']\n",
    "                debt_to_cover = liquidation_i.loc[0, 'debt_to_cover']\n",
    "                liquidated_collateral_amount = liquidation_i.loc[0, 'liquidated_collateral_amount']\n",
    "\n",
    "                liquidity_index = tmp_reserves_status[(tmp_reserves_status['reserve']==collateral_asset) & (tmp_reserves_status['block_n_index']<=block_n_index)]['liquidity_index'].values[-1]\n",
    "                variable_borrow_index = tmp_reserves_status[(tmp_reserves_status['reserve']==debt_asset) & (tmp_reserves_status['block_n_index']<=block_n_index)]['variable_borrow_index'].values[-1]\n",
    "                stable_borrow_rate = tmp_reserves_status[(tmp_reserves_status['reserve']==debt_asset) & (tmp_reserves_status['block_n_index']<=block_n_index)]['stable_borrow_rate'].values[-1]\n",
    "\n",
    "                # a_token_amount_i = ray_div(liquidated_collateral_amount, liquidity_index)\n",
    "                # collateral_dict[collateral_asset] -= a_token_amount_i\n",
    "\n",
    "                collateral_in_original_unit, var_debt_in_original_unit, sta_debt_in_original_unit = get_token_value(\n",
    "                    block_num, index,\n",
    "                    collateral_dict, collatearl_able_dict, variable_debt_dict, stable_debt_dict,reserves_status\n",
    "                )\n",
    "\n",
    "                if var_debt_in_original_unit[debt_asset] < debt_to_cover:\n",
    "                    var_debt_to_liquidate = var_debt_in_original_unit[debt_asset]\n",
    "                    sta_debt_to_repay = debt_to_cover - var_debt_to_liquidate\n",
    "                else:\n",
    "                    var_debt_to_liquidate = debt_to_cover\n",
    "                    sta_debt_to_repay = 0\n",
    "\n",
    "                success, remaining_token = update_target_debt_data(\n",
    "                        \"Repay\", block_num, var_debt_to_liquidate, debt_asset, \n",
    "                        \"2\", liquidity_index, variable_borrow_index, stable_borrow_rate,\n",
    "                        collateral_dict, collatearl_able_dict, variable_debt_dict, stable_debt_dict\n",
    "                    )\n",
    "                assert success\n",
    "\n",
    "                if sta_debt_to_repay > 0:\n",
    "                    success, remaining_token = update_target_debt_data(\n",
    "                        \"Repay\", block_num, sta_debt_to_repay, debt_asset, \n",
    "                        \"1\", liquidity_index, variable_borrow_index, stable_borrow_rate,\n",
    "                        collateral_dict, collatearl_able_dict, variable_debt_dict, stable_debt_dict\n",
    "                    )\n",
    "                    assert success\n",
    "                \n",
    "                success, remaining_token = update_target_debt_data(\n",
    "                    \"Withdraw\", block_num, liquidated_collateral_amount, collateral_asset, \n",
    "                    \"-1\", liquidity_index, variable_borrow_index, stable_borrow_rate,\n",
    "                    collateral_dict, collatearl_able_dict, variable_debt_dict, stable_debt_dict\n",
    "                )\n",
    "                assert success\n",
    "\n",
    "            else:\n",
    "                amount_i = sub_interaction_df.loc[index_i, 'amount']\n",
    "                token_name_i = sub_interaction_df.loc[index_i, 'reserve']\n",
    "                rate_mode_i = sub_interaction_df.loc[index_i, 'rate_mode']\n",
    "\n",
    "                liquidity_index = tmp_reserves_status[(tmp_reserves_status['reserve']==token_name_i) & (tmp_reserves_status['block_n_index']<=block_n_index)]['liquidity_index'].values[-1]\n",
    "                variable_borrow_index = tmp_reserves_status[(tmp_reserves_status['reserve']==token_name_i) & (tmp_reserves_status['block_n_index']<=block_n_index)]['variable_borrow_index'].values[-1]\n",
    "                stable_borrow_rate = tmp_reserves_status[(tmp_reserves_status['reserve']==token_name_i) & (tmp_reserves_status['block_n_index']<=block_n_index)]['stable_borrow_rate'].values[-1]\n",
    "\n",
    "                update_target_debt_data(action_i, block_num, amount_i, token_name_i, \n",
    "                rate_mode_i, liquidity_index, variable_borrow_index, stable_borrow_rate,\n",
    "                collateral_dict, collatearl_able_dict, variable_debt_dict, stable_debt_dict)\n",
    "            # print(sub_interaction_df.loc[index_i, :])\n",
    "            \n",
    "            if print_info: print(\"liquidity_index, variable_borrow_index, stable_borrow_rate\")\n",
    "            if print_info: print(liquidity_index, variable_borrow_index, stable_borrow_rate)\n",
    "            if print_info: print(\"collateral_dict, collatearl_able_dict, variable_debt_dict, stable_debt_dict\")\n",
    "            if print_info: print(collateral_dict, collatearl_able_dict, variable_debt_dict, stable_debt_dict)\n",
    "            \n",
    "            if print_info: print('---------------------------------------------------------------')\n",
    "        \n",
    "        if update_value:\n",
    "            if print_info: print(get_token_value(until_block_num, until_index, \n",
    "                                collateral_dict, collatearl_able_dict, variable_debt_dict, stable_debt_dict,\n",
    "                                reserves_status,\n",
    "                                fix_decimal=True\n",
    "                            ))\n",
    "\n",
    "        if block_n_index is None:\n",
    "            continue\n",
    "        curent_block_index = block_n_index\n",
    "        \n",
    "        # if not have_data: continue\n",
    "        if len(variable_debt_dict) == 0 and len(stable_debt_dict) == 0: continue\n",
    "        # if : continue\n",
    "        # print(tmp_block_num)\n",
    "        if tmp_block_num < (ReservesStatusEnd - PreviousBlockForTrain): continue\n",
    "        # print(999)\n",
    "        if tmp_block_num > (ReservesStatusEnd + StepAhead): break\n",
    "\n",
    "        \n",
    "        token_value_dicts = get_token_value(until_block_num, until_index, \n",
    "                                collateral_dict, collatearl_able_dict, variable_debt_dict, stable_debt_dict,\n",
    "                                reserves_status,\n",
    "                                fix_decimal=True\n",
    "                            )\n",
    "\n",
    "        # collateral, var_debt, sta_debt\n",
    "        token_value_dicts = {i:j for i,j in zip(['collateral', 'var_debt', 'sta_debt'], token_value_dicts)}\n",
    "        if print_info: print(token_value_dicts)\n",
    "\n",
    "        price_data = get_price_data(until_block_num, previous_block= 6424*1)\n",
    "        # price_data = get_price_data(until_block_num, previous_block=PreviousBlockForTrain)\n",
    "        price_data['token0'] = price_data['token0'].apply(lambda x: 'weth' if x == 'eth' else x)\n",
    "        price_data['token1'] = price_data['token1'].apply(lambda x: 'weth' if x == 'eth' else x)\n",
    "        price_data = price_data[['block_num', 'oracle_name', 'token0', 'token1', 'current']]\n",
    "\n",
    "        block_num_df = pd.DataFrame(\n",
    "            range(\n",
    "                price_data.block_num.min(), \n",
    "                until_block_num + 1\n",
    "            ),\n",
    "            columns=['block_num']\n",
    "        )\n",
    "        block_num_df.set_index('block_num', inplace=True)\n",
    "\n",
    "        uniswapv3_price_dict = {}\n",
    "        for token in ['usdt', 'dai', 'usdc']:\n",
    "            sub_price_df = price_data[(price_data['oracle_name'] == 'uniswapv3') & (price_data['token1'] == token)].copy()\n",
    "            sub_price_df[f'{token}'] = 1/sub_price_df['current']\n",
    "            sub_price_df.set_index('block_num', inplace=True)\n",
    "            sub_price_df = sub_price_df.merge(block_num_df, how='right', left_index=True, right_index=True)\n",
    "            sub_price_df.fillna(method='ffill', inplace=True)\n",
    "            sub_price_df.fillna(method='bfill', inplace=True)\n",
    "            sub_price_df = sub_price_df[sub_price_df.index > (until_block_num-10)]\n",
    "            uniswapv3_price_dict[token] = sub_price_df[token]\n",
    "        chainlink_price_dict ={}\n",
    "        for token in ['usdt', 'dai', 'usdc']:\n",
    "            sub_price_df = price_data[(price_data['oracle_name'] == 'chainlink') & (price_data['token0'] == token)].copy()\n",
    "            sub_price_df[f'{token}'] = sub_price_df['current']\n",
    "            sub_price_df.set_index('block_num', inplace=True)\n",
    "            sub_price_df = sub_price_df.merge(block_num_df, how='right', left_index=True, right_index=True)\n",
    "            sub_price_df.fillna(method='ffill', inplace=True)\n",
    "            sub_price_df.fillna(method='bfill', inplace=True)\n",
    "            sub_price_df = sub_price_df[sub_price_df.index > (until_block_num-10)]\n",
    "            chainlink_price_dict[token] = sub_price_df[token]\n",
    "\n",
    "        # collatearl_in_eth = 0\n",
    "        # debt_in_eth = 0\n",
    "        # for token_name, token_amount in token_value_dicts['collateral'].items():\n",
    "        #     if token_name == 'weth':\n",
    "        #         collatearl_in_eth += token_amount\n",
    "        #     else:\n",
    "        #         collatearl_in_eth += token_amount * chainlink_price_dict[token_name].loc[until_block_num]\n",
    "\n",
    "        # for token_name, token_amount in token_value_dicts['var_debt'].items():\n",
    "        #     if token_name == 'weth':\n",
    "        #         debt_in_eth += token_amount\n",
    "        #     else:\n",
    "        #         debt_in_eth += token_amount * chainlink_price_dict[token_name].loc[until_block_num]\n",
    "\n",
    "        # for token_name, token_amount in token_value_dicts['sta_debt'].items():\n",
    "        #     if token_name == 'weth':\n",
    "        #         debt_in_eth += token_amount\n",
    "        #     else:\n",
    "        #         debt_in_eth += token_amount * chainlink_price_dict[token_name].loc[until_block_num]\n",
    "\n",
    "        # collatearl_m_threshold_in_eth = 0\n",
    "        # debt_m_threshold_in_eth = 0\n",
    "        # for token_name, token_amount in token_value_dicts['collateral'].items():\n",
    "        #     if token_name == 'weth':\n",
    "        #         collatearl_m_threshold_in_eth += token_amount * liquidation_threshold_dict[token_name]\n",
    "        #     else:\n",
    "        #         collatearl_m_threshold_in_eth += token_amount * chainlink_price_dict[token_name].loc[until_block_num]  * liquidation_threshold_dict[token_name]\n",
    "\n",
    "        # for token_name, token_amount in token_value_dicts['var_debt'].items():\n",
    "        #     if token_name == 'weth':\n",
    "        #         debt_m_threshold_in_eth += token_amount\n",
    "        #     else:\n",
    "        #         debt_m_threshold_in_eth += token_amount * chainlink_price_dict[token_name].loc[until_block_num]\n",
    "\n",
    "        # for token_name, token_amount in token_value_dicts['sta_debt'].items():\n",
    "        #     if token_name == 'weth':\n",
    "        #         debt_m_threshold_in_eth += token_amount\n",
    "        #     else:\n",
    "        #         debt_m_threshold_in_eth += token_amount * chainlink_price_dict[token_name].loc[until_block_num]\n",
    "        # # collatearl_m_threshold_in_eth, debt_m_threshold_in_eth\n",
    "\n",
    "        # # testtt = interaction_df[['action', 'block_num', 'reserve', 'amount']]\n",
    "\n",
    "        # current_healthfactor = (collatearl_m_threshold_in_eth/debt_m_threshold_in_eth)\n",
    "\n",
    "        used_token_list = []\n",
    "        price_data_list = []\n",
    "        price_name_list = []\n",
    "        for asset_from in ['collateral', 'var_debt', 'sta_debt']:\n",
    "            for token_name in ['usdc', 'usdt', 'dai']:\n",
    "            # for token_name, token_amount in token_value_dicts[asset_from].items():\n",
    "                if token_name == 'weth': continue\n",
    "                if token_name not in used_token_list:\n",
    "                    used_token_list.append(token_name)\n",
    "                    price_data_list.append(chainlink_price_dict[token_name])\n",
    "                    price_name_list.append(f'chainlink_{token_name}')\n",
    "                    price_data_list.append(uniswapv3_price_dict[token_name])\n",
    "                    price_name_list.append(f'uniswapv3_{token_name}')\n",
    "\n",
    "        var_train_df = pd.concat(price_data_list, axis=1)\n",
    "        var_train_df.columns = price_name_list\n",
    "        var_train_df = var_train_df.reset_index(drop=False)\n",
    "\n",
    "        hf_actual_series = cal_hf(var_train_df, token_value_dicts, liquidation_threshold_dict)\n",
    "        block_list.append(tmp_block_num)\n",
    "        hf_list.append(hf_actual_series.iloc[-1])\n",
    "    hf_df = pd.DataFrame({'block_num': block_list, 'hf': hf_list})\n",
    "    return hf_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get Liquidation Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "change_token_address_to_name = lambda x: revert_token_dict[x] if x in revert_token_dict else x\n",
    "reserves_status = get_reserves_status()\n",
    "liquidation_data = get_liquidation_call()\n",
    "liquidation_data = liquidation_data.iloc[:,2:]\n",
    "\n",
    "np.random.seed(99)\n",
    "liquidation_data = liquidation_data.loc[np.random.choice(liquidation_data.index, 1000)]\n",
    "i = 0\n",
    "price_data_start_from = 12469311\n",
    "def vaidate_data(df_row):\n",
    "    interaction_df = get_interaction_data(df_row.loc['on_behalf_of'])\n",
    "    token_ok = interaction_df['reserve'].apply(change_token_address_to_name).apply(lambda x: len(x) <= 10).all()\n",
    "    collateral_ok = interaction_df[interaction_df['action']=='Deposit']['reserve'].apply(change_token_address_to_name).apply(lambda x: x != 'usdt').all()\n",
    "    no_swap = interaction_df['action'].apply(lambda x: x != 'Swap').all()\n",
    "    have_price_data = interaction_df['block_num'].apply(lambda x: x > price_data_start_from).all()\n",
    "    return token_ok and collateral_ok and no_swap and have_price_data\n",
    "valid_data_bool = liquidation_data.parallel_apply(vaidate_data, axis=1)\n",
    "liquidation_data_ok = liquidation_data[valid_data_bool]\n",
    "liquidation_data_ok = liquidation_data_ok.reset_index(drop=True).iloc[:100,:]\n",
    "liquidation_data_ok"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 3\n",
    "step_ahead = 10\n",
    "step_before = -1\n",
    "mc_amount = 100\n",
    "reserves_status_end_index = 9999\n",
    "# previous_block_for_train = 10\n",
    "\n",
    "\n",
    "tmp_data = liquidation_data_ok.iloc[i,:]\n",
    "\n",
    "hf_list = gen_real_hf(\n",
    "    reserves_status[(reserves_status['block_num']>(13550124-6424)) & (reserves_status['block_num']<tmp_data['block_num'] - step_before)],\n",
    "    TargetContract = tmp_data['on_behalf_of'],\n",
    "    ReservesStatusEnd = tmp_data['block_num'] - step_before,\n",
    "    StepAhead = step_ahead,\n",
    "    ReservesStatusEndIndex = reserves_status_end_index,\n",
    "    # PreviousBlockForTrain = previous_block_for_train\n",
    ")\n",
    "tmp_block_num, hf_list = hf_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 8\n",
    "step_ahead = 200\n",
    "reserves_status_end_index = 9999\n",
    "\n",
    "tmp_data = liquidation_data_ok.iloc[i,:]\n",
    "\n",
    "hf_list = gen_real_hf(\n",
    "    reserves_status[reserves_status['block_num']<15366765],\n",
    "    TargetContract = tmp_data['on_behalf_of'],\n",
    "    ReservesStatusEnd = 15366765,\n",
    "    StepAhead = step_ahead,\n",
    "    ReservesStatusEndIndex = reserves_status_end_index,\n",
    "    print_info=False\n",
    ")\n",
    "tmp_block_num, hf_list = hf_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(hf_list).plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "liquidation_data_ok"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# step_ahead = 1\n",
    "# reserves_status_end_index = 9999\n",
    "# mc_amount = 11\n",
    "# pre_block_train = 1\n",
    "\n",
    "# def test_valid_data(df_row):\n",
    "#     reserves_status_end = df_row['block_num']\n",
    "#     try:\n",
    "#         hf_df = gen_real_hf(\n",
    "#             reserves_status,\n",
    "#             TargetContract = df_row['on_behalf_of'],\n",
    "#             ReservesStatusEnd = reserves_status_end,\n",
    "#             StepAhead = step_ahead,\n",
    "#             ReservesStatusEndIndex = reserves_status_end_index,\n",
    "#             PreviousBlockForTrain = pre_block_train, \n",
    "#             print_info=False\n",
    "#         )\n",
    "#         return True\n",
    "#     except AssertionError:\n",
    "#         return False\n",
    "\n",
    "# valid_df = liquidation_data_ok.parallel_apply(test_valid_data, axis=1)\n",
    "# valid_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "step_ahead = 1\n",
    "reserves_status_end_index = 9999\n",
    "mc_amount = 1\n",
    "pre_block_train = 1\n",
    "data_i_list = []\n",
    "\n",
    "for i in range(liquidation_data_ok.shape[0]):\n",
    "    print(i)\n",
    "    tmp_data = liquidation_data_ok.iloc[i,:]\n",
    "    reserves_status_end = tmp_data['block_num']\n",
    "    try:\n",
    "        hf_df = gen_real_hf(\n",
    "            reserves_status,\n",
    "            TargetContract = tmp_data['on_behalf_of'],\n",
    "            ReservesStatusEnd = reserves_status_end,\n",
    "            StepAhead = step_ahead,\n",
    "            ReservesStatusEndIndex = reserves_status_end_index,\n",
    "            PreviousBlockForTrain = pre_block_train, \n",
    "            print_info=False\n",
    "        )\n",
    "    except AssertionError:\n",
    "        continue\n",
    "    data_i_list.append(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "liquidation_data_evl = liquidation_data_ok.iloc[data_i_list,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "liquidation_data_evl.to_csv('evl.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "liquidation_data_evl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(data_i_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "step_ahead = 200\n",
    "reserves_status_end_index = 9999\n",
    "mc_amount = 100\n",
    "pre_block_train = 1000\n",
    "# data_i_list = []\n",
    "data_list = []\n",
    "\n",
    "for i in data_i_list[:10]:\n",
    "    \n",
    "    tmp_data = liquidation_data_ok.iloc[i,:]\n",
    "    reserves_status_end = tmp_data['block_num']\n",
    "\n",
    "    try:\n",
    "        hf_df = gen_real_hf(\n",
    "            reserves_status,\n",
    "            TargetContract = tmp_data['on_behalf_of'],\n",
    "            ReservesStatusEnd = reserves_status_end,\n",
    "            StepAhead = step_ahead,\n",
    "            ReservesStatusEndIndex = reserves_status_end_index,\n",
    "            PreviousBlockForTrain = pre_block_train, \n",
    "            print_info=False\n",
    "        )\n",
    "    except AssertionError:\n",
    "        continue\n",
    "    # data_i_list.append(i)\n",
    "\n",
    "    sim_hf_df = gen_predict_hf(\n",
    "        reserves_status,\n",
    "        TargetContract = tmp_data['on_behalf_of'], \n",
    "        ReservesStatusEnd = reserves_status_end,\n",
    "        StepAhead = step_ahead, \n",
    "        MCAmount = mc_amount, \n",
    "        ReservesStatusEndIndex = reserves_status_end_index, \n",
    "        PreviousBlockForTrain = pre_block_train,\n",
    "    )\n",
    "    data_list.append(hf_df, sim_hf_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>block_num</th>\n",
       "      <th>hf</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>14955725</td>\n",
       "      <td>1.006450</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>14955726</td>\n",
       "      <td>1.096985</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   block_num        hf\n",
       "0   14955725  1.006450\n",
       "1   14955726  1.096985"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hf_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "step_ahead = 1010\n",
    "reserves_status_end_index = 9999\n",
    "mc_amount = 100\n",
    "pre_block_train = 1000\n",
    "end_before = 1000\n",
    "def apply_real_hf(df_row):\n",
    "    reserves_status_end = df_row['block_num']\n",
    "    hf_df = gen_real_hf(\n",
    "        reserves_status,\n",
    "        TargetContract = df_row['on_behalf_of'],\n",
    "        ReservesStatusEnd = reserves_status_end - end_before,\n",
    "        StepAhead = step_ahead,\n",
    "        ReservesStatusEndIndex = reserves_status_end_index,\n",
    "        PreviousBlockForTrain = pre_block_train, \n",
    "        print_info=False\n",
    "    )\n",
    "    return ','.join(map(str, hf_df['block_num'].to_list())) + ';' + ','.join(map(str, hf_df['hf'].to_list()))\n",
    "def apply_sim_hf(df_row):\n",
    "    reserves_status_end = df_row['block_num']\n",
    "    sim_hf_df = gen_predict_hf(\n",
    "        reserves_status,\n",
    "        TargetContract = df_row['on_behalf_of'], \n",
    "        ReservesStatusEnd = reserves_status_end - end_before,\n",
    "        StepAhead = step_ahead, \n",
    "        MCAmount = mc_amount, \n",
    "        ReservesStatusEndIndex = reserves_status_end_index, \n",
    "        PreviousBlockForTrain = pre_block_train,\n",
    "    )\n",
    "    return ','.join(map(str, sim_hf_df['block_num'].to_list())) + ';' + ','.join(map(str, sim_hf_df['hf'].to_list()))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8b49bff6520249c7a37b3aed4a4a1ed5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HBox(children=(IntProgress(value=0, description='0.00%', max=1), Label(value='0 / 1'))), HBox(c…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████| 1641224/1641224 [00:57<00:00, 28623.10it/s]\n",
      "100%|█████████████████████████████████████████████████████| 2827424/2827424 [01:02<00:00, 45454.48it/s]\n",
      "100%|█████████████████████████████████████████████████████| 3478345/3478345 [01:02<00:00, 55223.76it/s]\n",
      "100%|█████████████████████████████████████████████████████| 3378891/3378891 [01:04<00:00, 52296.11it/s]\n",
      "100%|█████████████████████████████████████████████████████| 3580394/3580394 [01:04<00:00, 55726.73it/s]\n",
      "100%|█████████████████████████████████████████████████████| 3832270/3832270 [01:05<00:00, 58775.26it/s]\n",
      "100%|█████████████████████████████████████████████████████| 3396365/3396365 [01:30<00:00, 37663.23it/s]\n",
      "100%|█████████████████████████████████████████████████████| 3596363/3596363 [01:32<00:00, 38997.93it/s]\n"
     ]
    }
   ],
   "source": [
    "tqdm.tqdm.pandas()\n",
    "# sim_hf_result = liquidation_data_evl.progress_apply(apply_sim_hf, axis=1)\n",
    "hf_result = liquidation_data_evl.parallel_apply(apply_real_hf, axis=1)\n",
    "\n",
    "with open('real_hf_result.pickle', 'wb') as handle:\n",
    "    pickle.dump(hf_result, handle, protocol=pickle.HIGHEST_PROTOCOL)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    15195242,15195243,15195244,15195245,15195246,1...\n",
       "1    14943366,14943367,14943368,14943369,14943370,1...\n",
       "2    14190396,14190397,14190398,14190399,14190400,1...\n",
       "3    14959335,14959336,14959337,14959338,14959339,1...\n",
       "4    14741863,14741864,14741865,14741866,14741867,1...\n",
       "5    14841317,14841318,14841319,14841320,14841321,1...\n",
       "6    13004196,13004197,13004198,13004199,13004200,1...\n",
       "8    14759337,14759338,14759339,14759340,14759341,1...\n",
       "dtype: object"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hf_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:>"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXoAAAD4CAYAAADiry33AAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjQuMywgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/MnkTPAAAACXBIWXMAAAsTAAALEwEAmpwYAAAUvUlEQVR4nO3df4xlZX3H8feX3cEtYIuyUwM7my4osUVThS661qalaitsdfkXEkuLNZsm2xabJg22SYn/tYkxam2gRJHQmiUptZUaSiX+CLEN2OWHdHG1rMW6F7A7YopNCXLPPd/+cc/MTteZnQXO4Xnu8H4lk917z9073z3P7uc+89zvfU5kJpKkjeuU0gVIkoZl0EvSBmfQS9IGZ9BL0gZn0EvSBre5dAGr2bp1a+7YsaN0GZI0M+67777vZeb8aseqDPodO3Zw4MCB0mVI0syIiP9c65hLN5K0wRn0krTBGfSStMFVuUa/mvF4zGg04plnnildypq2bNnCwsICc3NzpUuRpGUzE/Sj0YiXv/zl7Nixg4goXc6PyEyefPJJRqMR5557bulyJGnZzCzdPPPMM5x11llVhjxARHDWWWdV/ROHpJemmQl6oNqQX1J7fZJemmZm6UbS7PqXb32Pe771ZOkyqnfayzbz27/06t6f16B/Du68806uueYaJpMJ73vf+7j22mtLlyTNhD/7x2/wtdFT+EPviW0942UGfUmTyYR9+/Zx1113sbCwwMUXX8yePXu44IILSpcmVe+HTcs7X/cq/vLXd5Yu5SVpptboS/rqV7/Ka17zGs477zxOPfVUrrjiCj772c+WLkuaCeNJy+ZNxk0pMzmj/+A/PMzXH/9Br895wTk/znXvft2axx977DG2b9++fHthYYF777231xqkjappk7lTXLcpxZfYk7TatXXtspFOTjNJZ/QFzeSM/kQz76EsLCxw5MiR5duj0YhzzjnnRa9DmkXjScvcJidGpfgSe5IuvvhiHnnkER599FGeffZZbr31Vvbs2VO6LGkmNG2yyaWbYmZyRl/C5s2b+fjHP8473/lOJpMJ733ve3nd6178nyykWTSetGw+xXllKQb9c7B79252795dugxp5jSTdOmmIF9iJQ2uaW2vLMkzL2lQmcl4YntlSTMV9Ku1ONak9vqkEibt9P+FM/pyZubMb9myhSeffLLaMF3aj37Lli2lS5Gq0iwHvTP6UmbmzdiFhQVGoxGLi4ulS1nT0hWmJB0znrQAzNl1U8zMBP3c3JxXbpJmUDNxRl/aui+xEXFTRByNiINrHI+I+FhEHI6IhyLiohXHfj8iHo6IgxGxPyJc15BeYsbtdEbvGn05J3PmbwYuPcHxy4Dzu6+9wPUAEbEN+D1gZ2a+HtgEXPFCipU0e5Zm9HbdlLNu0Gfm3cD3T/CQy4Fbcuoe4MyIOLs7thn4sYjYDJwGPP5CC5Y0W44t3TijL6WPM78NOLLi9gjYlpmPAR8CvgM8ATyVmZ9f60kiYm9EHIiIAzW/4SrpuVlauvGTseX0EfSrjV5GxCuYzvbPBc4BTo+I96z1JJl5Y2buzMyd8/PzPZQlqQbLM3q7borp48yPgO0rbi8wXaJ5B/BoZi5m5hj4DPDzPXw/STNkqb3Srpty+gj624Gruu6bXUyXaJ5gumSzKyJOi+kVOt4OHOrh+0maIUsfmHLpppx1++gjYj9wCbA1IkbAdcAcQGbeANwB7AYOA08DV3fH7o2I24D7gQZ4ALix/7+CpJo1SzN6l26KWTfoM/PKdY4nsG+NY9cxfWGQ9BI19gNTxfkSK2lQzXLXjXFTimde0qCOdd04oy/FoJc0qOVNzZzRF+OZlzQotykuz6CXNKixXTfFeeYlDWp5UzNn9MUY9JIG1bhNcXGeeUmDGrtNcXEGvaRBLX8y1hl9MZ55SYOy66Y8g17SoI4t3Rg3pXjmJQ2qcZvi4gx6SYMat26BUJpBL2lQzaRl8ynB9LIUKsGglzSopk2XbQoz6CUNajxpfSO2MM++pEE1E2f0pRn0kgbVtK0flirMsy9pUONJuv1BYQa9pEE1E2f0pXn2JQ1qbNdNcQa9pEE1dt0U59mXNCi7bsoz6CUNarp0Y9SU5NmXNKjp0o0z+pIMekmDcummPINe0qDGbcucSzdFefYlDaqZpFsUF2bQSxrU2A9MFefZlzSopk3mXKMvyqCXNKjphUeMmpI8+5IGNbbrpjiDXtKgmtYtEErz7EsalH305Rn0kgY1nthHX5pnX9KgmtY++tLWDfqIuCkijkbEwTWOR0R8LCIOR8RDEXHRimNnRsRtEfGNiDgUEW/ps3hJ9Zsu3TinLOlkzv7NwKUnOH4ZcH73tRe4fsWxjwJ3ZuZPA28ADj2/MiXNqukWCM7oS9q83gMy8+6I2HGCh1wO3JKZCdzTzeLPBv4X+EXgN7vneRZ49gVXLGlmTNokE/voC+vj7G8Djqy4PeruOw9YBD4VEQ9ExCci4vQevp+kGTGetAB23RTWR9CvNoLJ9KeFi4DrM/NCpjP8a9d8koi9EXEgIg4sLi72UJak0po2AVy6KayPoB8B21fcXgAe7+4fZea93f23MQ3+VWXmjZm5MzN3zs/P91CWpNKapRm9SzdF9XH2bweu6rpvdgFPZeYTmfld4EhEvLZ73NuBr/fw/STNiPHEGX0N1n0zNiL2A5cAWyNiBFwHzAFk5g3AHcBu4DDwNHD1ij/+u8CnI+JU4D+OOyZpg2vapTV6Z/QlnUzXzZXrHE9g3xrHHgR2Pq/KJM28ppvR+4GpsnyZlTSYpa4bt0Aoy7MvaTBLXTe2V5Zl0EsazNiumyp49iUNprHrpgoGvaTB2HVTB8++pMEs99HbdVOUQS9pMMvtlc7oi/LsSxrMuHVTsxoY9JIGs/xmrF03RXn2JQ2mcZviKhj0kgYzdpviKhj0kgbjNsV18OxLGsyxrhtn9CUZ9JIGs9R146ZmZXn2JQ3GbYrrYNBLGsyxi4MbNSV59iUNxouD18GglzQYu27q4NmXNBgvDl4Hg17SYJq2ZdMpQYRBX5JBL2kwzSTtuKmAQS9pMONJ2kNfAUdA0mCatvVTsRUw6CUNZjxJO24q4AhIGkwzae24qYBBL2kwTZsu3VTAoJc0mPGk9epSFXAEJA2mmTijr4FBL2kwTdv6ZmwFHAFJg5n20TujL82glzSYSZtuUVwBR0DSYMaT1i0QKmDQSxpM07oFQg0cAUmDaSZugVADg17SYNwCoQ6OgKTBNK1bINTAoJc0mOkHpoyZ0tYdgYi4KSKORsTBNY5HRHwsIg5HxEMRcdFxxzdFxAMR8bm+ipY0G8Zty5xdN8WdzEvtzcClJzh+GXB+97UXuP6449cAh55PcZJmm1sg1GHdoM/Mu4Hvn+AhlwO35NQ9wJkRcTZARCwAvwZ8oo9iJc2WsUs3VehjBLYBR1bcHnX3AXwE+EOgXe9JImJvRByIiAOLi4s9lCWptMalmyr0EfSrjWJGxLuAo5l538k8SWbemJk7M3Pn/Px8D2VJKs03Y+vQxwiMgO0rbi8AjwNvBfZExLeBW4G3RcRf9/D9JM2IsR+YqkIfQX87cFXXfbMLeCozn8jMD2TmQmbuAK4AvpiZ7+nh+0maEU2bXnikApvXe0BE7AcuAbZGxAi4DpgDyMwbgDuA3cBh4Gng6qGKlTQ7MrPbvdIZfWnrBn1mXrnO8QT2rfOYLwNffi6FSZpt40kCuKlZBRwBSYNo2mmzndsUl2fQSxrE0ozerpvyHAFJg2gm0xm9m5qVZ9BLGkTTdjN6u26KcwQkDWLczejtuinPoJc0iGa568agL82glzSIY103xkxpjoCkQYyd0VfDoJc0iKWlm03O6ItzBCQNYtz6ZmwtDHpJg1h+M9YZfXGOgKRBNLZXVsOglzSIceubsbUw6CUNYnlG79JNcY6ApEEc29TMGX1pBr2kQSx9YMr96MtzBCQNYqnrxv3oyzPoJQ1iPHFGXwtHQNIglrcpdo2+OINe0iDsuqmHIyBpEG5qVg+DXtIglrcpdo2+OEdA0iDGdt1Uw6CXNIhjV5gyZkpzBCQNomlbImCTM/riDHpJgxhP0i2KK+EoSBpEM2ntoa+EQS9pEE2bvhFbCYNe0iDGk9Y3YivhKEgaRDNJl24qYdBLGsS4bd3+oBKOgqRBNJN0+4NKGPSSBtG0rdsfVMJRkDSI8cSum1oY9JIG0dh1Uw1HQdIgmtaum1oY9JIGMZ60boFQiXVHISJuioijEXFwjeMRER+LiMMR8VBEXNTdvz0ivhQRhyLi4Yi4pu/iJdXLPvp6nMzL7c3ApSc4fhlwfve1F7i+u78B/iAzfwbYBeyLiAuef6mSZsm4TbtuKrHuKGTm3cD3T/CQy4Fbcuoe4MyIODszn8jM+7vn+B/gELCtj6Il1a+ZtMzZdVOFPl5utwFHVtwecVygR8QO4ELg3rWeJCL2RsSBiDiwuLjYQ1mSSnLpph59BP1qI5nLByPOAP4WeH9m/mCtJ8nMGzNzZ2bunJ+f76EsSSWN/cBUNfoYhRGwfcXtBeBxgIiYYxryn87Mz/TwvSTNiGaSLt1Uoo+gvx24quu+2QU8lZlPREQAnwQOZeaHe/g+kmbI9MIjzuhrsHm9B0TEfuASYGtEjIDrgDmAzLwBuAPYDRwGngau7v7oW4FfB/4tIh7s7vujzLyjx/olVWrcuqlZLdYN+sy8cp3jCexb5f6vsPr6vaSXgGbiNsW1cBQkDcKum3oY9JIGMW7d1KwWjoKkQTRuU1wNg15S7zKz273SiKmBoyCpd007/cykffR1MOgl9a6ZTIPeGX0dHAVJvRu3LYB99JUw6CX1bnlG79JNFQx6Sb1rJtMZvUs3dXAUJPVuvPRmrEs3VTDoJfVueUbvFghVcBQk9W683HXjjL4GBr2k3jXLXTdGTA0cBUm9s+umLga9pN6NJ87oa+IoSOrd0hYIrtHXwaCX1LuxXTdVcRQk9W5pjd4++joY9JJ6t9R14ydj6+AoSOrd2K6bqhj0knp3bOnGiKmBoyCpd8eWbpzR18Cgl9S7paWbObtuquAoSOrdsW2KndHXwKCX1LuxH5iqikEvqXdLM3qXburgKEjqXeM2xVUx6CX1buw2xVVxFCT1zm2K62LQS+rd0hr9JoO+Cga9pN6N22RuUxBh0NfAoJfUu2bSukVxRRwJSb0bT9KOm4oY9JJ617StHTcVcSQk9a6ZpB03FTHoJfVuPEln9BXZXLqAPr37z7/CM+PJ8/7z2WMtAM5n9FL13aee4ZVnnFq6DHXWDfqIuAl4F3A0M1+/yvEAPgrsBp4GfjMz7++OXdod2wR8IjP/tMfaf8Sr50/n2a5/9/mKnuI5e3/ZkGbH+a86g7e8emvpMtQ5mRn9zcDHgVvWOH4ZcH739WbgeuDNEbEJ+AvgV4AR8K8RcXtmfv2FFr2Wj1xx4VBPLUkza91FtMy8G/j+CR5yOXBLTt0DnBkRZwNvAg5n5n9k5rPArd1jJUkvoj7eLdkGHFlxe9Tdt9b9q4qIvRFxICIOLC4u9lCWJAn6CfrVFrXzBPevKjNvzMydmblzfn6+h7IkSdBP180I2L7i9gLwOHDqGvdLkl5EfczobweuiqldwFOZ+QTwr8D5EXFuRJwKXNE9VpL0IjqZ9sr9wCXA1ogYAdcBcwCZeQNwB9PWysNM2yuv7o41EfE7wD8xba+8KTMfHuDvIEk6gXWDPjOvXOd4AvvWOHYH0xcCSVIhfkZZkja4mE7I6xIRi8B/Ps8/vhX4Xo/l9KXWuqDe2mqtC+qtrda6oN7aaq0LnlttP5WZq7YsVhn0L0REHMjMnaXrOF6tdUG9tdVaF9RbW611Qb211VoX9FebSzeStMEZ9JK0wW3EoL+xdAFrqLUuqLe2WuuCemurtS6ot7Za64Keattwa/SSpP9vI87oJUkrGPSStMFtmKCPiEsj4psRcTgiri1cy00RcTQiDq6475URcVdEPNL9+ooCdW2PiC9FxKGIeDgirqmoti0R8dWI+FpX2wdrqa2rY1NEPBARn6usrm9HxL9FxIMRcaCW2iLizIi4LSK+0f17e0sldb22O1dLXz+IiPdXUtvvd//2D0bE/u7/RC91bYigX3E1q8uAC4ArI+KCgiXdDFx63H3XAl/IzPOBL3S3X2wN8AeZ+TPALmBfd55qqO2HwNsy8w3AG4FLu03yaqgN4Brg0IrbtdQF8MuZ+cYV/dY11PZR4M7M/GngDUzPXfG6MvOb3bl6I/BzTPfn+rvStUXENuD3gJ3dJVs3Md0Isp+6MnPmv4C3AP+04vYHgA8UrmkHcHDF7W8CZ3e/Pxv4ZgXn7bNML/VYVW3AacD9TC9NWbw2pltsfwF4G/C5msYT+Daw9bj7itYG/DjwKF2zRy11rVLnrwL/XENtHLtQ0yuZ7kH2ua6+XuraEDN6nuPVrAp5VU63b6b79SdLFhMRO4ALgXuppLZueeRB4ChwV2bWUttHgD8EVl55voa6YHoxn89HxH0RsbeS2s4DFoFPdctdn4iI0yuo63hXAPu73xetLTMfAz4EfAd4gul275/vq66NEvTP6WpWL3URcQbwt8D7M/MHpetZkpmTnP5IvQC8KSJeX7gkIuJdwNHMvK90LWt4a2ZexHTZcl9E/GLpgpjOSC8Crs/MC4H/pezS1o/orpGxB/ib0rUAdGvvlwPnAucAp0fEe/p6/o0S9Gtd5aom/9VdNJ3u16MlioiIOaYh/+nM/ExNtS3JzP8Gvsz0fY7Stb0V2BMR32Z6gfu3RcRfV1AXAJn5ePfrUaZrzW+qoLYRMOp+IgO4jWnwl65rpcuA+zPzv7rbpWt7B/BoZi5m5hj4DPDzfdW1UYJ+Fq5mdTvwG93vf4Pp+viLKiIC+CRwKDM/XFlt8xFxZvf7H2P6D/8bpWvLzA9k5kJm7mD67+qLmfme0nUBRMTpEfHypd8zXdM9WLq2zPwucCQiXtvd9Xbg66XrOs6VHFu2gfK1fQfYFRGndf9P3870Dex+6ir5ZkjPb2bsBv4d+Bbwx4Vr2c90nW3MdHbzW8BZTN/Qe6T79ZUF6voFpktaDwEPdl+7K6ntZ4EHutoOAn/S3V+8thU1XsKxN2OL18V0Lfxr3dfDS//uK6ntjcCBbjz/HnhFDXV1tZ0GPAn8xIr7itcGfJDp5OYg8FfAy/qqyy0QJGmD2yhLN5KkNRj0krTBGfSStMEZ9JK0wRn0krTBGfSStMEZ9JK0wf0fhPQ4/x2/nU4AAAAASUVORK5CYII=",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "pd.DataFrame(map(float, hf_result[4].split(';')[1].split(','))).plot()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Django Shell-Plus",
   "language": "python",
   "name": "django_extensions"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "b0ef27b5998537e6e8a4cc2d81c0ef50c5704a9340d6613576e42e6548a03246"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
